{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a85a57",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258cfb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-13 12:03:54.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Admin\\Documents\\GitHub\\sams\u001b[0m\n",
      "\u001b[32m2025-11-13 12:03:54.711\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msams.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - \u001b[33m\u001b[1mGoogle MAPS API key not found, using Nominatim geocoder\u001b[0m\n",
      "\u001b[32m2025-11-13 12:03:54.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mLoaded 0 geocodes from cache\u001b[0m\n",
      "\u001b[32m2025-11-13 12:03:54.711\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msams.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - \u001b[33m\u001b[1mGoogle MAPS API key not found, using Nominatim geocoder\u001b[0m\n",
      "\u001b[32m2025-11-13 12:03:54.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mLoaded 0 geocodes from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sams.utils import load_data\n",
    "from sams.config import datasets\n",
    "import gc\n",
    "import polars as pl\n",
    "import duckdb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e77e8",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load student records from SQLite database and parquet files across all education modules (ITI, Diploma, HSS, DEG, CHSE, BSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345f130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: ['students', 'institutes', 'results']\n"
     ]
    }
   ],
   "source": [
    "# Use the path from datasets metadata \n",
    "db_path = datasets[\"sams\"][\"path\"]\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tables:\", [t[0] for t in tables])\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedb3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = datasets[\"sams\"][\"path\"]\n",
    "\n",
    "# Load ITI + Diploma\n",
    "conn = sqlite3.connect(db_path)\n",
    "query = \"\"\"\n",
    "SELECT academic_year, aadhar_no, student_name, dob,\n",
    "       admission_status, mark_data, module\n",
    "FROM students\n",
    "WHERE module IN ('ITI', 'Diploma');\n",
    "\"\"\"\n",
    "students_df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Extract needed keys (first entry only)\n",
    "keep_keys = [\"YearofPassing\", \"RollNo\", \"ExaminationType\",\n",
    "             \"HighestQualificationExamBoard\", \"ExamName\"]\n",
    "\n",
    "def extract_mark(row):\n",
    "    md = row[\"mark_data\"]\n",
    "    try:\n",
    "        md = json.loads(md) if isinstance(md, str) else md\n",
    "        if isinstance(md, dict): md = [md]\n",
    "    except:\n",
    "        md = []\n",
    "    rec = md[0] if isinstance(md, list) and md else {}\n",
    "    return {k: rec.get(k) for k in keep_keys}\n",
    "\n",
    "mark_df = pd.json_normalize(students_df.apply(extract_mark, axis=1))\n",
    "\n",
    "# Merge + rename\n",
    "df = pd.concat([students_df.drop(columns=[\"mark_data\"]),\n",
    "                mark_df.rename(columns={\n",
    "                    \"YearofPassing\": \"passing_year\",\n",
    "                    \"RollNo\": \"roll_no\",\n",
    "                    \"ExaminationType\": \"exam_type\",\n",
    "                    \"HighestQualificationExamBoard\": \"exam_board\",\n",
    "                    \"ExamName\": \"exam_name\"\n",
    "                })],\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304306c",
   "metadata": {},
   "source": [
    "### 1.1 ITI and Diploma Data\n",
    "\n",
    "- Load ITI and Diploma student records from database\n",
    "- Parse JSON mark data to extract roll numbers and exam details\n",
    "- Filter Diploma to include only students with 10th standard as highest qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e084dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITI (all rows)\n",
    "iti_enrollments = df[df[\"module\"] == \"ITI\"].reset_index(drop=True)\n",
    "\n",
    "# Diploma (ONLY exam_name = \"10th\")\n",
    "diploma_enrollments = (\n",
    "    df[(df[\"module\"] == \"Diploma\") &\n",
    "       (df[\"exam_name\"].str.lower() == \"10th\")]\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42fb6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dob in iti_enrollments to YYYY-MM-DD format\n",
    "iti_enrollments['dob'] = pd.to_datetime(iti_enrollments['dob'], format=\"%d-%b-%Y\", errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "diploma_enrollments['dob'] = pd.to_datetime(diploma_enrollments['dob'], format=\"%d-%b-%Y\", errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "iti_marks = load_data(datasets['iti_marks'])\n",
    "diploma_marks = load_data(datasets['diploma_marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd8f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df in parquet format\n",
    "DATA_DIR = Path(\"C:/Users/Admin/Documents/GitHub/sams/data\")\n",
    "RAW_DATA_DIR = DATA_DIR / \"interim\"\n",
    "iti_applications = pd.read_parquet(RAW_DATA_DIR / \"iti_applications.pq\")\n",
    "diploma_applications = pd.read_parquet(RAW_DATA_DIR / \"diploma_applications.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4379690",
   "metadata": {},
   "source": [
    "### 1.2 HSS and DEG Data\n",
    "\n",
    "- Load Higher Secondary School (HSS) and Degree (DEG) enrollment and application records from parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac21297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-13 12:06:41.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\hss_enrollments.pq\u001b[0m\n",
      "\u001b[32m2025-11-13 12:07:27.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\deg_enrollments.pq\u001b[0m\n",
      "\u001b[32m2025-11-13 12:07:27.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\deg_enrollments.pq\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hss_enrollments = load_data(datasets[\"hss_enrollments\"])\n",
    "deg_enrollments = load_data(datasets[\"deg_enrollments\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0b4288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-13 12:08:06.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\deg_applications.pq\u001b[0m\n",
      "\u001b[32m2025-11-13 12:08:19.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\hss_applications.pq\u001b[0m\n",
      "\u001b[32m2025-11-13 12:08:19.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msams.utils\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoading data from C:\\Users\\Admin\\Documents\\GitHub\\sams\\data\\interim\\hss_applications.pq\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "deg_applications = load_data(datasets[\"deg_applications\"])\n",
    "hss_applications = load_data(datasets[\"hss_applications\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb957a",
   "metadata": {},
   "source": [
    "### 1.3 CHSE and BSE Results Data\n",
    "\n",
    "- Load Council of Higher Secondary Education (CHSE) and Board of Secondary Education (BSE) result records from database\n",
    "- Assign appropriate exam board names based on module type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34816c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = datasets[\"sams\"][\"path\"]\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    academic_year,\n",
    "    student_name,\n",
    "    dob,\n",
    "    module,\n",
    "    CASE \n",
    "        WHEN module = 'CHSE' THEN 'CHSE, Odisha'\n",
    "        WHEN module = 'BSE' THEN 'BSE, Odisha'\n",
    "        ELSE NULL\n",
    "    END AS exam_board,\n",
    "    academic_year AS passing_year,    \n",
    "    roll_no,\n",
    "    NULL AS roll_no_decrypted,\n",
    "    exam_type\n",
    "    \n",
    "FROM results\n",
    "WHERE module IN ('CHSE', 'BSE');\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Split into CHSE and BSE datasets\n",
    "chse_df = df[df[\"module\"] == \"CHSE\"].reset_index(drop=True)\n",
    "bse_df  = df[df[\"module\"] == \"BSE\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c623411",
   "metadata": {},
   "outputs": [],
   "source": [
    "bse_df[\"dob\"] = pd.to_datetime(bse_df[\"dob\"], format=\"%d-%b-%Y\", errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "chse_df['exam_type'] = chse_df['exam_type'].replace({'REGULAR': 'annual'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34c8e2",
   "metadata": {},
   "source": [
    "## 2. Roll Number Processing\n",
    "\n",
    "**Function:** `decrypt_roll()` and `process_roll_numbers_len_format()`\n",
    "\n",
    "Decrypt encrypted roll numbers and validate them using board-specific length rules:\n",
    "- **BSE (10th standard):** Must be exactly 9 digits\n",
    "- **CHSE (12th standard):** Must be exactly 8 digits\n",
    "- Invalid or mismatched rolls are marked as \"NA\"\n",
    "\n",
    "**Logic:**\n",
    "- Decrypt roll numbers using AES encryption (ECB mode)\n",
    "- Apply regex matching to identify BSE and CHSE Odisha boards\n",
    "- Validate decrypted roll numbers against expected length for each board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90592cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for decryption\n",
    "from base64 import b64decode\n",
    "from Crypto.Cipher import AES\n",
    "\n",
    "def decrypt_roll(enc_text: str,\n",
    "                 key: bytes = b\"y6idXfCVRG5t2dkeBnmHy9jLu6TEn5Du\",\n",
    "                 enforce_min_length: bool = False,\n",
    "                 min_length: int = None) -> str:\n",
    "    try:\n",
    "        if not enc_text or not isinstance(enc_text, str):\n",
    "            return \"NA\"\n",
    "\n",
    "        raw = b64decode(enc_text)\n",
    "        cipher = AES.new(key, AES.MODE_ECB)\n",
    "        decrypted = cipher.decrypt(raw)\n",
    "\n",
    "        pad_len = decrypted[-1]\n",
    "        if pad_len < 1 or pad_len > 16:\n",
    "            return \"NA\"\n",
    "        decrypted = decrypted[:-pad_len]\n",
    "\n",
    "        roll_no = decrypted.decode(\"utf-8\").strip()\n",
    "        return roll_no\n",
    "    except Exception:\n",
    "        return \"NA\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b2c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_roll_numbers_len_format(df: pd.DataFrame, roll_col: str = 'roll_no') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Decrypt roll numbers and validate only by length rule:\n",
    "    - BSE Odisha: length must be 9\n",
    "    - CHSE Odisha: length must be 8\n",
    "    - Other boards: keep decrypted roll as-is\n",
    "    \"\"\"\n",
    "\n",
    "    # Decrypt roll numbers\n",
    "    df['roll_no_decrypted'] = df[roll_col].map(decrypt_roll)\n",
    "\n",
    "    # Identify Odisha boards \n",
    "    board_col = df['exam_board'].fillna(\"NA\").str.upper()\n",
    "    # Put the condition to pass these input values of board name        \n",
    "    mask_bse = (board_col.str.contains(r'\\bBOARD OF SECONDARY EDUCATION,\\s*ODISHA\\b', regex=True)  \n",
    "                | (board_col.str.contains(r'\\bBSE\\b(?! MADHYAMA).*ODISHA\\b', regex=True) & ~board_col.str.contains(r'\\bICSE\\b|\\bCBSE\\b', regex=True)))\n",
    "    \n",
    "    mask_chse = (board_col.str.contains(r'\\bCOUNCIL OF HIGHER SECONDARY EDUCATION,\\s*ODISHA\\b', regex=True) \n",
    "                 | board_col.str.contains(r'\\bCHSE\\b.*ODISHA\\b', regex=True))\n",
    "\n",
    "    # Apply validation\n",
    "    if mask_bse.any():\n",
    "        rolls_bse = df.loc[mask_bse & df['roll_no_decrypted'].notna(), 'roll_no_decrypted'].astype(str)\n",
    "        valid_bse = rolls_bse.str.len() == 9\n",
    "        df.loc[mask_bse & ~valid_bse, 'roll_no_decrypted'] = 'NA'\n",
    "\n",
    "    if mask_chse.any():\n",
    "        rolls_chse = df.loc[mask_chse & df['roll_no_decrypted'].notna(), 'roll_no_decrypted'].astype(str)\n",
    "        valid_chse = rolls_chse.str.len() == 8\n",
    "        df.loc[mask_chse & ~valid_chse, 'roll_no_decrypted'] = 'NA'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c3031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep, then drop everything else and rename finally\n",
    "keep_cols = [\n",
    "    'barcode', 'aadhar_no', 'academic_year', 'module', 'student_name',\n",
    "    'dob', 'examination_board_of_the_highest_qualification','examination_type', 'year_of_passing' , 'roll_no'\n",
    "]\n",
    "hss_enrollments = hss_enrollments[keep_cols].copy()\n",
    "deg_enrollments = deg_enrollments[keep_cols].copy()\n",
    "rename_map = {\n",
    "    'examination_board_of_the_highest_qualification': 'exam_board',\n",
    "    'examination_type': 'exam_type',\n",
    "    'year_of_passing': 'passing_year'\n",
    "}\n",
    "hss_enroll = hss_enrollments.rename(columns=rename_map)\n",
    "deg_enroll = deg_enrollments.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58446d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "iti_df = process_roll_numbers_len_format(iti_enrollments)\n",
    "diploma_df = process_roll_numbers_len_format(diploma_enrollments)\n",
    "hss_df = process_roll_numbers_len_format(hss_enroll)\n",
    "deg_df = process_roll_numbers_len_format(deg_enroll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458b6f8",
   "metadata": {},
   "source": [
    "## 3. Student Key Generation\n",
    "\n",
    "**Function:** `generate_student_key_df()` (6-variable key)\n",
    "\n",
    "Create unique composite keys to identify students across datasets and academic years.\n",
    "\n",
    "**Key Components:**\n",
    "- Student name\n",
    "- Roll number (decrypted)\n",
    "- Date of birth\n",
    "- Passing year\n",
    "- Exam board\n",
    "- Exam type\n",
    "\n",
    "**Logic:**\n",
    "- Normalize all fields (lowercase, trim whitespace)\n",
    "- Concatenate fields with underscore separator\n",
    "- Calculate diagnostics: total records, unique keys, duplicate keys, unique Aadhaar numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1832a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_part(s: pd.Series, *, na_label=\"NA\", missing_label=\"MISSING\", lower=False) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Encode parts of a student key by handling missing/NA values consistently.\n",
    "    \"\"\"\n",
    "    is_nan = s.isna()\n",
    "    t = s.astype(str).str.strip()\n",
    "    t = t.str.strip('\"').str.strip(\"'\")   # remove quotes if present\n",
    "\n",
    "    out = t.copy()\n",
    "\n",
    "    # Replace explicit NA and missing values\n",
    "    out = out.mask(t.eq(\"NA\"), na_label)\n",
    "    out = out.mask(t.eq(\"\") | is_nan, missing_label)\n",
    "\n",
    "    # Normalize casing if requested\n",
    "    if lower:\n",
    "        out = out.where(out.isin([na_label, missing_label]), out.str.lower().str.strip())\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77118bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_student_key_df(df, module_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean key columns in-place, then generate a student_key\n",
    "    and print diagnostics about duplicates.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "\n",
    "    key_vars = [\"passing_year\", \"dob\",\n",
    "                \"roll_no_decrypted\", \"exam_board\", \"exam_type\"]\n",
    "\n",
    "    # Normalize and ensure all key parts are strings\n",
    "    for col in key_vars + [\"student_name\"]:\n",
    "        new_df[col] = new_df[col].astype(str).fillna(\"\").str.strip().str.lower()\n",
    "\n",
    "    # Construct student key safely\n",
    "    new_df[\"student_key\"] = (\n",
    "        new_df[\"student_name\"] + \"_\" +\n",
    "        new_df[\"roll_no_decrypted\"] + \"_\" +\n",
    "        new_df[\"dob\"] + \"_\" +\n",
    "        new_df[\"passing_year\"] + \"_\" +\n",
    "        new_df[\"exam_board\"] + \"_\" +\n",
    "        new_df[\"exam_type\"]\n",
    "    )\n",
    "\n",
    "    # Diagnostics\n",
    "    total_records = len(new_df)\n",
    "    unique_aadhar = new_df[\"aadhar_no\"].nunique(dropna=True)\n",
    "    unique_keys = new_df[\"student_key\"].nunique()\n",
    "\n",
    "    # Problematic duplicates = same key linked to multiple Aadhaar numbers\n",
    "    dup_check = (\n",
    "        new_df.groupby(\"student_key\")[\"aadhar_no\"]\n",
    "        .nunique(dropna=True)\n",
    "        .reset_index(name=\"unique_aadhar_count\")\n",
    "    )\n",
    "    problematic_keys = dup_check[dup_check[\"unique_aadhar_count\"] > 1][\"student_key\"]\n",
    "    duplicate_keys_count = len(problematic_keys)\n",
    "\n",
    "    print(f\"\\n[{module_name}]\")\n",
    "    print(\"Total student records:\", total_records)\n",
    "    print(\"Unique student keys generated:\", unique_keys)\n",
    "    print(\"Duplicate student keys:\", duplicate_keys_count)\n",
    "    print(\"Unique Aadhar numbers:\", unique_aadhar)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630499e",
   "metadata": {},
   "source": [
    "### 3.1 Student Key Generation (4-Variable)\n",
    "\n",
    "**Function:** `generate_student_key_four_var()` (4-variable key for CHSE and BSE)\n",
    "\n",
    "Generate module-specific student keys using 4 variables:\n",
    "- **CHSE:** roll_no + passing_year + exam_board + exam_type\n",
    "- **BSE:** roll_no + dob + passing_year + exam_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80c9825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_student_key_four_var(df: pd.DataFrame, module_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a standardized 4-variable student key (`student_key_4_var`) \n",
    "    for identity matching across datasets.\n",
    "\n",
    "    The key is built using module-specific rules:\n",
    "    - CHSE (Higher Secondary): roll_no_decrypted + passing_year + exam_board + exam_type\n",
    "    - BSE  (Secondary):        roll_no_decrypted + dob + passing_year + exam_board\n",
    "    - DEG  (Degree):           roll_no_decrypted + passing_year + exam_board + exam_type\n",
    "    - HSS  (Higher Secondary): roll_no_decrypted + dob + passing_year + exam_board\n",
    "\n",
    "    All fields are normalized (lowercase, stripped) before concatenation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame containing student records.\n",
    "    module_name : str\n",
    "        Module name (\"CHSE\", \"BSE\", \"DEG\", or \"HSS\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new column `student_key_4_var`\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    module = module_name.upper()\n",
    "\n",
    "    # Select key components based on module\n",
    "    if module in [\"CHSE\"]:\n",
    "        key_parts = [\"roll_no_decrypted\", \"passing_year\", \"exam_board\", \"exam_type\"]\n",
    "    elif module in [\"BSE\"]:\n",
    "        key_parts = [\"roll_no_decrypted\", \"dob\", \"passing_year\", \"exam_board\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid module '{module_name}'. Use 'CHSE', 'BSE', 'DEG', or 'HSS'.\")\n",
    "\n",
    "    # Normalize fields\n",
    "    for col in key_parts:\n",
    "        new_df[col] = (\n",
    "            new_df[col].astype(str).fillna(\"\").str.strip().str.lower()\n",
    "            if col in new_df.columns else \"\"\n",
    "        )\n",
    "\n",
    "    # Create composite key\n",
    "    new_df[\"student_key_4_var\"] = new_df[key_parts].agg(\"_\".join, axis=1)\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n[{module}] Student Key (4-var) Summary\")\n",
    "    print(\"Total records:\", len(new_df))\n",
    "    print(\"Unique keys:\", new_df[\"student_key_4_var\"].nunique())\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6838c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ITI]\n",
      "Total student records: 559575\n",
      "Unique student keys generated: 524796\n",
      "Duplicate student keys: 1807\n",
      "Unique Aadhar numbers: 518024\n",
      "\n",
      "[Diploma]\n",
      "Total student records: 445850\n",
      "Unique student keys generated: 414078\n",
      "Duplicate student keys: 4285\n",
      "Unique Aadhar numbers: 392904\n",
      "\n",
      "[Diploma]\n",
      "Total student records: 445850\n",
      "Unique student keys generated: 414078\n",
      "Duplicate student keys: 4285\n",
      "Unique Aadhar numbers: 392904\n",
      "\n",
      "[DEG]\n",
      "Total student records: 2054491\n",
      "Unique student keys generated: 1634565\n",
      "Duplicate student keys: 1917\n",
      "Unique Aadhar numbers: 1506304\n",
      "\n",
      "[DEG]\n",
      "Total student records: 2054491\n",
      "Unique student keys generated: 1634565\n",
      "Duplicate student keys: 1917\n",
      "Unique Aadhar numbers: 1506304\n"
     ]
    }
   ],
   "source": [
    "iti_key_df = generate_student_key_df(iti_df, \"ITI\")\n",
    "diploma_key_df = generate_student_key_df(diploma_df, \"Diploma\")\n",
    "hss_key_df = generate_student_key_df(hss_df, \"HSS\")\n",
    "deg_key_df = generate_student_key_df(deg_df, \"DEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c30a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HSS]\n",
      "Total student records: 3453401\n",
      "Unique student keys generated: 2961052\n",
      "Duplicate student keys: 5011\n",
      "Unique Aadhar numbers: 2650769\n"
     ]
    }
   ],
   "source": [
    "hss_key_df = generate_student_key_df(hss_df, \"HSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0db7c",
   "metadata": {},
   "source": [
    "### 3.2 Merge Enrollment with Applications\n",
    "\n",
    "**Function:** `merge_enrollment_applications()`\n",
    "\n",
    "Merge application-level data with student identity information from enrollment records using barcode as the key. Keeps all application rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "35fd38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_enrollment_applications(enroll_df, app_df):\n",
    "    \"\"\"\n",
    "    Merge application rows with student identity columns using barcode.\n",
    "    Keeps all application rows and adds student info from enrollment table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Columns we want from enrollment (as you listed)\n",
    "    enroll_cols = [\n",
    "        \"barcode\", \"student_name\", \"aadhar_no\", \"dob\", \"module\",\n",
    "        \"academic_year\", \"exam_board\", \"exam_type\", \"passing_year\",\n",
    "        \"roll_no\", \"roll_no_decrypted\", \"student_key\"\n",
    "    ]\n",
    "    \n",
    "    enroll_reduced = enroll_df[enroll_cols].copy()\n",
    "\n",
    "    # Only barcode from applications\n",
    "    app_reduced = app_df[[\"barcode\"]].copy()\n",
    "\n",
    "    # Merge keeping all application rows\n",
    "    merged = app_reduced.merge(enroll_reduced, on=\"barcode\", how=\"left\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5772f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "hss_df2 = merge_enrollment_applications(hss_key_df, hss_applications)\n",
    "deg_df2 = merge_enrollment_applications(deg_key_df, deg_applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b48d2a",
   "metadata": {},
   "source": [
    "## 4. Generate Keys and Calculate Summaries for BSE and CHSE\n",
    "\n",
    "Apply student key generation functions to all modules and calculate year-wise summaries of total observations and unique keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BSE] Student Key (4-var) Summary\n",
      "Total records: 1617255\n",
      "Unique keys: 1603360\n",
      "Unique keys: 1603360\n",
      "\n",
      "[CHSE] Student Key (4-var) Summary\n",
      "Total records: 1963873\n",
      "\n",
      "[CHSE] Student Key (4-var) Summary\n",
      "Total records: 1963873\n",
      "Unique keys: 1963873\n",
      "Unique keys: 1963873\n"
     ]
    }
   ],
   "source": [
    "bse_df = process_roll_numbers_len_format(bse_df)\n",
    "chse_df = process_roll_numbers_len_format(chse_df)\n",
    "bse_key_df = generate_student_key_four_var(bse_df, \"BSE\")\n",
    "chse_key_df = generate_student_key_four_var(chse_df, \"CHSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eebad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "academic_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_observations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_unique_keys",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5b01f4e1-3127-429b-9eef-ba409fbd2af9",
       "rows": [
        [
         "0",
         "2023",
         "541391",
         "537314"
        ],
        [
         "1",
         "2024",
         "563426",
         "553608"
        ],
        [
         "2",
         "2025",
         "512438",
         "512438"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_year</th>\n",
       "      <th>num_observations</th>\n",
       "      <th>num_unique_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>541391</td>\n",
       "      <td>537314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>563426</td>\n",
       "      <td>553608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>512438</td>\n",
       "      <td>512438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic_year  num_observations  num_unique_keys\n",
       "0           2023            541391           537314\n",
       "1           2024            563426           553608\n",
       "2           2025            512438           512438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count the total number of students acrooss all years for the both dtaset and check for unique student_key\n",
    "# table : Year | Num. observations | Num. unique key\n",
    "bse_summary = (\n",
    "    bse_key_df.groupby(\"academic_year\")\n",
    "    .agg(\n",
    "        student_count=(\"student_name\", \"size\"),\n",
    "        num_unique_keys=(\"student_key_4_var\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "bse_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9c9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "academic_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "student_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_unique_keys",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "66ab7f12-337c-4833-98e9-ec0d60811cc5",
       "rows": [
        [
         "0",
         "2020",
         "306230",
         "306230"
        ],
        [
         "1",
         "2021",
         "295178",
         "295178"
        ],
        [
         "2",
         "2022",
         "301650",
         "301650"
        ],
        [
         "3",
         "2023",
         "338220",
         "338220"
        ],
        [
         "4",
         "2024",
         "357825",
         "357825"
        ],
        [
         "5",
         "2025",
         "364770",
         "364770"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_year</th>\n",
       "      <th>student_count</th>\n",
       "      <th>num_unique_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>306230</td>\n",
       "      <td>306230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>295178</td>\n",
       "      <td>295178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>301650</td>\n",
       "      <td>301650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>338220</td>\n",
       "      <td>338220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>357825</td>\n",
       "      <td>357825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>364770</td>\n",
       "      <td>364770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic_year  student_count  num_unique_keys\n",
       "0           2020         306230           306230\n",
       "1           2021         295178           295178\n",
       "2           2022         301650           301650\n",
       "3           2023         338220           338220\n",
       "4           2024         357825           357825\n",
       "5           2025         364770           364770"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chse_summary = (\n",
    "    chse_key_df.groupby(\"academic_year\")\n",
    "    .agg(\n",
    "        student_count=(\"student_name\", \"size\"),\n",
    "        num_unique_keys=(\"student_key_4_var\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "chse_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87be18",
   "metadata": {},
   "source": [
    "## 5. Yearly Summaries (All Modules)\n",
    "\n",
    "Calculate unique Aadhaar and unique key counts across all academic years for HSS, DEG modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de268cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['barcode', 'student_name', 'aadhar_no', 'dob', 'module',\n",
       "       'academic_year', 'exam_board', 'exam_type', 'passing_year', 'roll_no',\n",
       "       'roll_no_decrypted', 'student_key'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hss_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0958c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "academic_year",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "hss_app",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hss_aadhar",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hss_key",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "deg_app",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "deg_aadhar",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "deg_key",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "df6192c1-7d98-4582-a203-d89e4a06d30b",
       "rows": [
        [
         "0",
         "2018",
         "2237155",
         "367579",
         "410423",
         "1519247",
         "204304",
         "246871"
        ],
        [
         "1",
         "2019",
         "2060027",
         "355307",
         "387103",
         "1669860",
         "200209",
         "224421"
        ],
        [
         "2",
         "2020",
         "2280404",
         "345900",
         "394490",
         "1594363",
         "191842",
         "221414"
        ],
        [
         "3",
         "2021",
         "2591931",
         "375367",
         "446480",
         "2176487",
         "250724",
         "257168"
        ],
        [
         "4",
         "2022",
         "2772098",
         "407112",
         "466993",
         "3199753",
         "256801",
         "268724"
        ],
        [
         "5",
         "2023",
         "3110640",
         "419134",
         "480728",
         "2233931",
         "236544",
         "242242"
        ],
        [
         "6",
         "2024",
         "6083906",
         "473096",
         "487117",
         "2246432",
         "262392",
         "268466"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_year</th>\n",
       "      <th>hss_app</th>\n",
       "      <th>hss_aadhar</th>\n",
       "      <th>hss_key</th>\n",
       "      <th>deg_app</th>\n",
       "      <th>deg_aadhar</th>\n",
       "      <th>deg_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2237155</td>\n",
       "      <td>367579</td>\n",
       "      <td>410423</td>\n",
       "      <td>1519247</td>\n",
       "      <td>204304</td>\n",
       "      <td>246871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2060027</td>\n",
       "      <td>355307</td>\n",
       "      <td>387103</td>\n",
       "      <td>1669860</td>\n",
       "      <td>200209</td>\n",
       "      <td>224421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>2280404</td>\n",
       "      <td>345900</td>\n",
       "      <td>394490</td>\n",
       "      <td>1594363</td>\n",
       "      <td>191842</td>\n",
       "      <td>221414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>2591931</td>\n",
       "      <td>375367</td>\n",
       "      <td>446480</td>\n",
       "      <td>2176487</td>\n",
       "      <td>250724</td>\n",
       "      <td>257168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>2772098</td>\n",
       "      <td>407112</td>\n",
       "      <td>466993</td>\n",
       "      <td>3199753</td>\n",
       "      <td>256801</td>\n",
       "      <td>268724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>3110640</td>\n",
       "      <td>419134</td>\n",
       "      <td>480728</td>\n",
       "      <td>2233931</td>\n",
       "      <td>236544</td>\n",
       "      <td>242242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>6083906</td>\n",
       "      <td>473096</td>\n",
       "      <td>487117</td>\n",
       "      <td>2246432</td>\n",
       "      <td>262392</td>\n",
       "      <td>268466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic_year  hss_app  hss_aadhar  hss_key  deg_app  deg_aadhar  deg_key\n",
       "0           2018  2237155      367579   410423  1519247      204304   246871\n",
       "1           2019  2060027      355307   387103  1669860      200209   224421\n",
       "2           2020  2280404      345900   394490  1594363      191842   221414\n",
       "3           2021  2591931      375367   446480  2176487      250724   257168\n",
       "4           2022  2772098      407112   466993  3199753      256801   268724\n",
       "5           2023  3110640      419134   480728  2233931      236544   242242\n",
       "6           2024  6083906      473096   487117  2246432      262392   268466"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HSS and DEG \n",
    "hss = hss_df2.groupby(\"academic_year\").agg(\n",
    "    hss_app=(\"academic_year\", \"size\"),\n",
    "    hss_aadhar=(\"aadhar_no\", \"nunique\"),\n",
    "    hss_key=(\"student_key\", \"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "deg = deg_df2.groupby(\"academic_year\").agg(\n",
    "    deg_app=(\"academic_year\", \"size\"),\n",
    "    deg_aadhar=(\"aadhar_no\", \"nunique\"),\n",
    "    deg_key=(\"student_key\", \"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "# Final merged table\n",
    "hss_deg_stats = hss.merge(deg, on=\"academic_year\")\n",
    "hss_deg_stats[\"academic_year\"] = hss_deg_stats[\"academic_year\"].astype(\"Int64\")\n",
    "hss_deg_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9a1ba",
   "metadata": {},
   "source": [
    "### 5.1 Clean Aadhaar Summary (HSS & DEG)\n",
    "\n",
    "**Function:** `yearly_clean_aadhar_summary()`\n",
    "\n",
    "Generate comprehensive yearly metrics for HSS and DEG modules:\n",
    "- Total Aadhaar entries (before cleaning)\n",
    "- Unique Aadhaar (after excluding null/placeholder values)\n",
    "- Missing Aadhaar count\n",
    "- 1-by-1 matches (clean identity matching)\n",
    "\n",
    "**Logic:**\n",
    "- Define bad values: empty strings, 'na', 'null', 'nan', etc.\n",
    "- Clean and normalize Aadhaar and student_key fields\n",
    "- Remove bad values and deduplicate pairs\n",
    "- Calculate one-to-one matches where both Aadhaar and key appear exactly once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55583d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_clean_aadhar_summary(df, prefix):\n",
    "\n",
    "    # fields we need\n",
    "    data = df[['academic_year', 'aadhar_no', 'student_key']].copy()\n",
    "\n",
    "    # Normalize strings (trim + lowercase)\n",
    "    for col in ['academic_year', 'aadhar_no', 'student_key']:\n",
    "        data[col] = data[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # Define what counts as an invalid entry\n",
    "    invalid_entries = {\"\", \"null\", \"nan\"}  \n",
    "\n",
    "    def summarize(year_df):\n",
    "\n",
    "        total_rows = len(year_df)\n",
    "        invalid_aadhar = year_df['aadhar_no'].isin(invalid_entries).sum()\n",
    "\n",
    "        # keep only rows with valid pairs\n",
    "        valid_rows = year_df[\n",
    "            (~year_df['aadhar_no'].isin(invalid_entries)) &\n",
    "            (~year_df['student_key'].isin(invalid_entries))\n",
    "        ].drop_duplicates(subset=['aadhar_no', 'student_key'])\n",
    "\n",
    "        unique_aadhar = valid_rows['aadhar_no'].nunique()\n",
    "\n",
    "        # identify one-to-one Aadhaar <-> student_key pairs\n",
    "        aadhar_counts = valid_rows['aadhar_no'].value_counts()\n",
    "        key_counts = valid_rows['student_key'].value_counts()\n",
    "\n",
    "        one_to_one = valid_rows[\n",
    "            valid_rows['aadhar_no'].isin(aadhar_counts[aadhar_counts == 1].index) &\n",
    "            valid_rows['student_key'].isin(key_counts[key_counts == 1].index)\n",
    "        ]\n",
    "\n",
    "        return pd.Series({\n",
    "            f\"{prefix}_total_aadhar\": total_rows,\n",
    "            f\"{prefix}_unique_aadhar\": unique_aadhar,\n",
    "            f\"{prefix}_invalid_aadhar\": invalid_aadhar,\n",
    "            f\"{prefix}_one_to_one\": len(one_to_one)\n",
    "        })\n",
    "\n",
    "    summary = (\n",
    "        data.groupby(\"academic_year\", group_keys=False)\n",
    "            .apply(summarize)\n",
    "            .reset_index()\n",
    "            .rename(columns={\"academic_year\": \"year\"})\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Run for HSS & DEG\n",
    "hss_clean = yearly_clean_aadhar_summary(hss_key_df, \"hss\")\n",
    "deg_clean = yearly_clean_aadhar_summary(deg_key_df, \"deg\")\n",
    "\n",
    "hss_deg_total_unique_invalid_aadhar_1by1match = (\n",
    "    hss_clean.merge(deg_clean, on=\"year\", how=\"outer\")\n",
    "             .sort_values(\"year\")\n",
    ")\n",
    "\n",
    "hss_deg_total_unique_invalid_aadhar_1by1match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed8604f",
   "metadata": {},
   "source": [
    "## 6. Data Quality Analysis\n",
    "\n",
    "Assess Aadhaar coverage, identify repeated entries, and evaluate identity matching quality across all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0565601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ITI ENROLLMENT: Repeated Aadhaar by Year ---\n",
      " academic_year                                    aadhar_no  count\n",
      "          2017 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=   3181\n",
      "          2018 UIC27nlODwzAwV13RAZD1vk8kiSxo2GLRDviArS4Ktg=     10\n",
      " academic_year                                    aadhar_no  count\n",
      "          2017 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=   3181\n",
      "          2018 UIC27nlODwzAwV13RAZD1vk8kiSxo2GLRDviArS4Ktg=     10\n"
     ]
    }
   ],
   "source": [
    "# repeat Aadhaar check by academic year\n",
    "def repeated_aadhaar_summary(df, module_name):\n",
    "    print(f\"\\n--- {module_name.upper()}: Repeated Aadhaar by Year ---\")\n",
    "    repeat_summary = (\n",
    "        df.groupby(['academic_year', 'aadhar_no'])\n",
    "          .size()\n",
    "          .reset_index(name='count')\n",
    "          .query('count > 5')  # Only keep Aadhaar appearing more than five times\n",
    "          .sort_values(['academic_year', 'count'], ascending=[True, False])\n",
    "    )\n",
    "    print(repeat_summary.to_string(index=False))\n",
    "\n",
    "# Run for ITI and Diploma\n",
    "repeated_aadhaar_summary(iti_enrollments, \"ITI ENROLLMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b7b08",
   "metadata": {},
   "source": [
    "### 6.1 Repeated Aadhaar Detection\n",
    "\n",
    "**Function:** `repeated_aadhaar_summary()`\n",
    "\n",
    "Identify Aadhaar numbers appearing more than 5 times within the same academic year (potential data quality issues or shared/placeholder values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbcd4d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DIPLOMA ENROLLMENT: Repeated Aadhaar by Year ---\n",
      " academic_year                                    aadhar_no  count\n",
      "          2018 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=  10118\n",
      "          2019 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=  13183\n",
      " academic_year                                    aadhar_no  count\n",
      "          2018 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=  10118\n",
      "          2019 47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=  13183\n"
     ]
    }
   ],
   "source": [
    "repeated_aadhaar_summary(diploma_enrollments, \"Diploma ENROLLMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "578186de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_from_enrollments(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    # Group by year + Aadhaar and count occurrences\n",
    "    repeats = (\n",
    "        df.groupby(['academic_year', 'aadhar_no'])\n",
    "          .size()\n",
    "          .reset_index(name='cnt')\n",
    "    )\n",
    "\n",
    "    # Keep rows where Aadhaar repeats (>1)\n",
    "    hashed = (\n",
    "        repeats[repeats['cnt'] > 1]\n",
    "            .groupby('academic_year')['cnt']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(columns={'cnt': f'{prefix}_missing_aadhar'})\n",
    "    )\n",
    "\n",
    "    return hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "643ec324",
   "metadata": {},
   "outputs": [],
   "source": [
    "iti_missing = missing_from_enrollments(iti_key_df, 'iti')\n",
    "dip_missing = missing_from_enrollments(diploma_key_df, 'diploma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "35ba2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITI missing (hashed):\n",
      " academic_year  iti_missing_aadhar\n",
      "          2017               10949\n",
      "          2018                8840\n",
      "          2020                   4\n",
      "\n",
      "Diploma missing (hashed):\n",
      " academic_year  diploma_missing_aadhar\n",
      "          2018                   12079\n",
      "          2019                   13329\n",
      "          2020                     107\n"
     ]
    }
   ],
   "source": [
    "print('ITI missing (hashed):')\n",
    "print(iti_missing.head(7).to_string(index=False))\n",
    "\n",
    "print('\\nDiploma missing (hashed):')\n",
    "print(dip_missing.head(7).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe069cd",
   "metadata": {},
   "source": [
    "### 6.2 Unreliable Aadhaar Index\n",
    "\n",
    "**Function:** `build_unreliable_aadhaar_index()`\n",
    "\n",
    "**Logic:**\n",
    "- Group by year and Aadhaar to count occurrences\n",
    "- Flag Aadhaar values exceeding threshold or matching known placeholders\n",
    "- Return DataFrame with unreliable Aadhaar marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fd939089",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_AADHAAR_PLACEHOLDERS = {\n",
    "    '47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=',  # common placeholder\n",
    "}\n",
    "\n",
    "def build_unreliable_aadhaar_index(df: pd.DataFrame,\n",
    "                                   per_year_threshold: int = 100,\n",
    "                                   known_placeholders: set[str] | None = None) -> pd.DataFrame:\n",
    "\n",
    "    known_placeholders = known_placeholders or set()\n",
    "\n",
    "    # Count occurrences per year\n",
    "    counts = (\n",
    "        df.groupby(['academic_year', 'aadhar_no'])\n",
    "          .size()\n",
    "          .reset_index(name='cnt')\n",
    "    )\n",
    "\n",
    "    # Aadhaar values that repeat above threshold\n",
    "    heavy = counts[counts['cnt'] >= per_year_threshold][['academic_year', 'aadhar_no']]\n",
    "\n",
    "    # Aadhaar values that match known placeholder hashes\n",
    "    known = counts[counts['aadhar_no'].isin(known_placeholders)][['academic_year', 'aadhar_no']]\n",
    "\n",
    "    # Combine\n",
    "    out = pd.concat([heavy, known]).drop_duplicates()\n",
    "    out['unreliable'] = True\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88c18b",
   "metadata": {},
   "source": [
    "**Function:** `summarize_clean_aadhaar()`\n",
    "\n",
    "Calculate yearly metrics after excluding unreliable Aadhaar values:\n",
    "- `unique_aadhar`: Count of unique reliable Aadhaar numbers\n",
    "- `supposed_missing`: Count of unreliable/placeholder Aadhaar\n",
    "- `non_unique_aadhar`: Count of Aadhaar that still repeat among reliable rows\n",
    "\n",
    "**Note:** This approach has limitations. Use `yearly_clean_aadhar_summary()` for more accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clean_aadhaar(df: pd.DataFrame,\n",
    "                            prefix: str,\n",
    "                            unreliable_idx: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    data = df[['academic_year', 'aadhar_no']].copy()\n",
    "\n",
    "    # Mark unreliable Aadhaar values\n",
    "    if unreliable_idx is not None and not unreliable_idx.empty:\n",
    "        data = data.merge(unreliable_idx, on=['academic_year', 'aadhar_no'], how='left')\n",
    "        data['unreliable'] = data['unreliable'].fillna(False)\n",
    "    else:\n",
    "        data['unreliable'] = False\n",
    "\n",
    "    data['supposed_missing'] = data['unreliable']\n",
    "\n",
    "    # Keep only reliable Aadhaar rows\n",
    "    reliable_rows = data[data['unreliable'] == False]\n",
    "\n",
    "    # Count unique reliable Aadhaar per year\n",
    "    unique_count = (\n",
    "        reliable_rows.groupby('academic_year')['aadhar_no']\n",
    "                     .nunique()\n",
    "                     .rename(f'{prefix}_unique_aadhar')\n",
    "    )\n",
    "\n",
    "    # Count Aadhaar that STILL repeat among reliable rows\n",
    "    repeated_count = (\n",
    "        reliable_rows.groupby(['academic_year', 'aadhar_no'])\n",
    "                     .size()\n",
    "                     .reset_index(name='cnt')\n",
    "                     .query('cnt > 1')\n",
    "                     .groupby('academic_year')\n",
    "                     .size()\n",
    "                     .rename(f'{prefix}_non_unique_aadhar')\n",
    "    )\n",
    "\n",
    "    # Count unreliable rows per year\n",
    "    missing_count = (\n",
    "        data.groupby('academic_year')['supposed_missing']\n",
    "            .sum()\n",
    "            .rename(f'{prefix}_supposed_missing')\n",
    "    )\n",
    "\n",
    "    # Combine results\n",
    "    summary = (\n",
    "        pd.concat([unique_count, missing_count, repeated_count], axis=1)\n",
    "          .reset_index()\n",
    "          .fillna(0)\n",
    "    )\n",
    "\n",
    "    # Ensure numeric columns are int\n",
    "    for col in summary.columns:\n",
    "        if col != 'academic_year':\n",
    "            summary[col] = summary[col].astype(int)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7409517",
   "metadata": {},
   "source": [
    "### 6.3 Yearly summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb7dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly summary for ITI & Diploma with application counts\n",
    "def create_yearly_summary(enrollment_df, application_df):\n",
    "    \"\"\"\n",
    "    Generate yearly summary combining enrollment and application data.\n",
    "    \n",
    "    Parameters:\n",
    "    - enrollment_df: DataFrame with student_key and aadhar_no (from key generation)\n",
    "    - application_df: DataFrame with barcode for counting total applications\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count total applications by year\n",
    "    app_counts = (\n",
    "        application_df.groupby('academic_year')\n",
    "        .size()\n",
    "        .reset_index(name='total_applications')\n",
    "    )\n",
    "    \n",
    "    # Calculate Aadhaar and 1-by-1 match metrics from enrollment data\n",
    "    def _metrics(g):\n",
    "        mapping = g[['aadhar_no', 'student_key']].drop_duplicates()\n",
    "\n",
    "        # Find unique Aadhaar and unique keys within the year\n",
    "        unique_aadhar = mapping['aadhar_no'].value_counts() == 1\n",
    "        unique_key = mapping['student_key'].value_counts() == 1\n",
    "\n",
    "        # Count 1-by-1 matches (unique Aadhaar to unique key)\n",
    "        one_to_one = mapping[\n",
    "            mapping['aadhar_no'].isin(unique_aadhar[unique_aadhar].index) &\n",
    "            mapping['student_key'].isin(unique_key[unique_key].index)\n",
    "        ]\n",
    "\n",
    "        return pd.Series({\n",
    "            'aadhar': g['aadhar_no'].nunique(),\n",
    "            '1by1_match': len(one_to_one),\n",
    "        })\n",
    "\n",
    "    enroll_summary = (\n",
    "        enrollment_df.groupby('academic_year', group_keys=False)\n",
    "          .apply(_metrics)\n",
    "          .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Merge application counts with enrollment metrics\n",
    "    summary = app_counts.merge(enroll_summary, on='academic_year', how='outer')\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361e060",
   "metadata": {},
   "source": [
    "### 6.4 One-to-One Match Quality (ITI & Diploma)\n",
    "\n",
    "**Function:** `create_yearly_summary()`\n",
    "\n",
    "Calculate yearly identity matching quality metrics:\n",
    "- Total applications by year\n",
    "- Unique Aadhaar count\n",
    "- 1-by-1 matches (one Aadhaar maps to exactly one student key)\n",
    "\n",
    "**Logic:**\n",
    "- Count applications from application DataFrame\n",
    "- Deduplicate (Aadhaar, student_key) pairs within each year\n",
    "- Identify pairs where both Aadhaar and student_key appear exactly once\n",
    "- Merge application counts with enrollment metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26a77567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9772\\1316644817.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_metrics)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ITI Applications: 2,218,985\n",
      "Total Diploma Applications: 1,552,260.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9772\\1316644817.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_metrics)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "iti_applications",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "iti_aadhar",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "iti_1by1_match",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "diploma_applications",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diploma_aadhar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diploma_1by1_match",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a93ddc02-b291-434c-83a2-37bef5f2ec6a",
       "rows": [
        [
         "0",
         "2017",
         "145612",
         "27337",
         "26065",
         null,
         null,
         null
        ],
        [
         "1",
         "2018",
         "215662",
         "70613",
         "69617",
         "203293.0",
         "49934.0",
         "48543.0"
        ],
        [
         "2",
         "2019",
         "261505",
         "64148",
         "64119",
         "186285.0",
         "41590.0",
         "41484.0"
        ],
        [
         "3",
         "2020",
         "208581",
         "67412",
         "67407",
         "181710.0",
         "52959.0",
         "52868.0"
        ],
        [
         "4",
         "2021",
         "300121",
         "68000",
         "67974",
         "175738.0",
         "54979.0",
         "54949.0"
        ],
        [
         "5",
         "2022",
         "303082",
         "74104",
         "74077",
         "244165.0",
         "71768.0",
         "71747.0"
        ],
        [
         "6",
         "2023",
         "388380",
         "92085",
         "92069",
         "270782.0",
         "73513.0",
         "73503.0"
        ],
        [
         "7",
         "2024",
         "396042",
         "83958",
         "83958",
         "290287.0",
         "76694.0",
         "76682.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>iti_applications</th>\n",
       "      <th>iti_aadhar</th>\n",
       "      <th>iti_1by1_match</th>\n",
       "      <th>diploma_applications</th>\n",
       "      <th>diploma_aadhar</th>\n",
       "      <th>diploma_1by1_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>145612</td>\n",
       "      <td>27337</td>\n",
       "      <td>26065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>215662</td>\n",
       "      <td>70613</td>\n",
       "      <td>69617</td>\n",
       "      <td>203293.0</td>\n",
       "      <td>49934.0</td>\n",
       "      <td>48543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>261505</td>\n",
       "      <td>64148</td>\n",
       "      <td>64119</td>\n",
       "      <td>186285.0</td>\n",
       "      <td>41590.0</td>\n",
       "      <td>41484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>208581</td>\n",
       "      <td>67412</td>\n",
       "      <td>67407</td>\n",
       "      <td>181710.0</td>\n",
       "      <td>52959.0</td>\n",
       "      <td>52868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>300121</td>\n",
       "      <td>68000</td>\n",
       "      <td>67974</td>\n",
       "      <td>175738.0</td>\n",
       "      <td>54979.0</td>\n",
       "      <td>54949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>303082</td>\n",
       "      <td>74104</td>\n",
       "      <td>74077</td>\n",
       "      <td>244165.0</td>\n",
       "      <td>71768.0</td>\n",
       "      <td>71747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>388380</td>\n",
       "      <td>92085</td>\n",
       "      <td>92069</td>\n",
       "      <td>270782.0</td>\n",
       "      <td>73513.0</td>\n",
       "      <td>73503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>396042</td>\n",
       "      <td>83958</td>\n",
       "      <td>83958</td>\n",
       "      <td>290287.0</td>\n",
       "      <td>76694.0</td>\n",
       "      <td>76682.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  iti_applications  iti_aadhar  iti_1by1_match  diploma_applications  \\\n",
       "0  2017            145612       27337           26065                   NaN   \n",
       "1  2018            215662       70613           69617              203293.0   \n",
       "2  2019            261505       64148           64119              186285.0   \n",
       "3  2020            208581       67412           67407              181710.0   \n",
       "4  2021            300121       68000           67974              175738.0   \n",
       "5  2022            303082       74104           74077              244165.0   \n",
       "6  2023            388380       92085           92069              270782.0   \n",
       "7  2024            396042       83958           83958              290287.0   \n",
       "\n",
       "   diploma_aadhar  diploma_1by1_match  \n",
       "0             NaN                 NaN  \n",
       "1         49934.0             48543.0  \n",
       "2         41590.0             41484.0  \n",
       "3         52959.0             52868.0  \n",
       "4         54979.0             54949.0  \n",
       "5         71768.0             71747.0  \n",
       "6         73513.0             73503.0  \n",
       "7         76694.0             76682.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summaries for ITI and Diploma\n",
    "iti_summary = create_yearly_summary(iti_key_df, iti_applications)\n",
    "diploma_summary = create_yearly_summary(diploma_key_df, diploma_applications)\n",
    "\n",
    "final_summary = (\n",
    "    iti_summary.merge(\n",
    "        diploma_summary, on='academic_year',how='outer', suffixes=('_iti', '_diploma'))\n",
    "    )\n",
    "\n",
    "# Rename columns for clarity\n",
    "final_summary = final_summary.rename(columns={\n",
    "    'academic_year': 'year',\n",
    "    'total_applications_iti': 'iti_applications',\n",
    "    'aadhar_iti': 'iti_aadhar',\n",
    "    '1by1_match_iti': 'iti_1by1_match',\n",
    "    'total_applications_diploma': 'diploma_applications',\n",
    "    'aadhar_diploma': 'diploma_aadhar',\n",
    "    '1by1_match_diploma': 'diploma_1by1_match',\n",
    "})\n",
    "\n",
    "# Final column ordering\n",
    "final_summary = final_summary[\n",
    "    [\n",
    "        'year',\n",
    "        'iti_applications', 'iti_aadhar', 'iti_1by1_match',\n",
    "        'diploma_applications', 'diploma_aadhar', 'diploma_1by1_match', \n",
    "    ]\n",
    "]\n",
    "\n",
    "# Print total applications across all years\n",
    "print(f\"Total ITI Applications: {final_summary['iti_applications'].sum():,}\")\n",
    "print(f\"Total Diploma Applications: {final_summary['diploma_applications'].sum():,}\\n\")\n",
    "\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7fdca",
   "metadata": {},
   "source": [
    "### 6.5 Unique Key count for ITI and Diploma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4136624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unique_key_iti",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unique_key_diploma",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0fc06a38-e7f2-49b5-8837-0778eb070ef2",
       "rows": [
        [
         "0",
         "2018",
         "71194",
         "58826"
        ],
        [
         "1",
         "2019",
         "64133",
         "54726"
        ],
        [
         "2",
         "2020",
         "67413",
         "52982"
        ],
        [
         "3",
         "2021",
         "67987",
         "54964"
        ],
        [
         "4",
         "2022",
         "74090",
         "71757"
        ],
        [
         "5",
         "2023",
         "92077",
         "73508"
        ],
        [
         "6",
         "2024",
         "83958",
         "76688"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>unique_key_iti</th>\n",
       "      <th>unique_key_diploma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>71194</td>\n",
       "      <td>58826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>64133</td>\n",
       "      <td>54726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>67413</td>\n",
       "      <td>52982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>67987</td>\n",
       "      <td>54964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>74090</td>\n",
       "      <td>71757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>92077</td>\n",
       "      <td>73508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>83958</td>\n",
       "      <td>76688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  unique_key_iti  unique_key_diploma\n",
       "0  2018           71194               58826\n",
       "1  2019           64133               54726\n",
       "2  2020           67413               52982\n",
       "3  2021           67987               54964\n",
       "4  2022           74090               71757\n",
       "5  2023           92077               73508\n",
       "6  2024           83958               76688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iti = iti_key_df.groupby('academic_year').agg(\n",
    "    unique_key=('student_key', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "diploma = diploma_key_df.groupby('academic_year').agg(\n",
    "    unique_key=('student_key', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "iti.merge(diploma, on='academic_year', suffixes=('_iti', '_diploma')).rename(columns={'academic_year': 'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766f520",
   "metadata": {},
   "source": [
    "## 5. Methodology Summary\n",
    "\n",
    "Overview of the data quality validation approach and key concepts used in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6d545",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Student Key Generation\n",
    "\n",
    "**Main_goal:** Create unique key for students across different module and check for the 1by1 match with present aadhar\n",
    "\n",
    "**Approach:**\n",
    "- Concatenate multiple fields to create a composite key\n",
    "- Fields used: name + roll_no + dob + passing_year + exam_board + exam_type\n",
    "- All fields are normalized (lowercase, stripped) for consistency\n",
    "- Missing values are handled consistently with \"MISSING\" or \"NA\" labels\n",
    "\n",
    "\n",
    "### 2. Roll Number Decryption and Validation\n",
    "\n",
    "**Process:**\n",
    "1. **Decryption:** Use AES encryption with ECB mode to decrypt Base64-encoded roll numbers\n",
    "2. **Validation:** Apply board-specific length rules:\n",
    "   - BSE (10th standard): Must be exactly 9 digits\n",
    "   - CHSE (12th standard): Must be exactly 8 digits\n",
    "3. **Invalid handling:** Mark invalid rolls as \"NA\" to prevent incorrect matches\n",
    "\n",
    "\n",
    "### 3. Aadhaar Quality Assessment\n",
    "\n",
    "\n",
    "**Problems with Aadhaar data:**\n",
    "- **Missing values:** Same Aadhaar used for multiple students (hashed placeholders)\n",
    "\n",
    "**Solution - Unreliable Aadhaar Index:**\n",
    "- Flag Aadhaar values appearing >100 times in a single year \n",
    "\n",
    "**Metrics calculated:**\n",
    "- `unique_aadhar`: Distinct Aadhaar after excluding unreliable ones\n",
    "- `supposed_missing`: Count of null or unreliable Aadhaar\n",
    "- `non_unique_aadhar`: Count of Aadhaar IDs still appearing multiple times (WHICH WAS WRONG CONCEPT TO CALCULATE)\n",
    "\n",
    "### 4. One-to-One (1-by-1) Matching\n",
    "\n",
    "\n",
    "**Definition:**\n",
    "A 1-by-1 match occurs when:\n",
    "- One Aadhaar number maps to exactly one student key (within a year)\n",
    "\n",
    "**Algorithm:**\n",
    "1. Create mapping of (Aadhaar, student_key) pairs\n",
    "2. Count occurrences of each Aadhaar and each student_key\n",
    "3. Keep only pairs where both appear exactly once\n",
    "\n",
    "### 5. Yearly Aggregation Strategy\n",
    "\n",
    "**Key metrics tracked yearly:**\n",
    "- Applications: Total application records\n",
    "- Unique Aadhaar: Distinct valid Aadhaar numbers\n",
    "- Unique Keys: Distinct student identifiers generated\n",
    "- 1-by-1 Matches: Clean identity matches\n",
    "- Missing/Unreliable: Data quality issues\n",
    "\n",
    "\n",
    "### 6. Module-Specific Considerations\n",
    "\n",
    "**ITI (Industrial Training Institute):**\n",
    "- Higher missing Aadhaar rates expected, the hash one, loaded from db\n",
    "\n",
    "**Diploma:**\n",
    "- Filtered to 10th pass students only, loaded from db\n",
    "\n",
    "**HSS (Higher Secondary School):**\n",
    "**DEG (Degree):**\n",
    "- Both has been imported from pipeline and then merge enrollment to applications dataset on the barcode to include all columns from enrollments dataset at application level\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
